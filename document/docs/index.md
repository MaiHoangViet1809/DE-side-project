# EDW - Documentation

***

## Getting started

This project contain framework to operate Data warehouse, Data Lake using Airflow as orchestrator, 
included frontend to manage user and mini tool relative to data operation.

***

## Installation

There are 2 deployment approach for UDT:

- Python via WSL1 on Windows Virtual Machine (Currently approach)
    - start airflow using script in this path: source airflow_deployment/python_env_wsl1/start-airflow.sh
- Docker-composer


***

## Roadmap

- migrate to BIGDATA fully using spark + object storage in Azure

## Teams:

- Initial Project: Mai Hoang Viet.
- Sponsors: Ngo Tien Thinh.
- Internal staffs:
    * Bui Thanh Nam
    * Pham Ngoc Trong
    * Vo Danh Long
    * Do Tram Anh

## Project status
Production stage, start to cutoff data using new DB

***